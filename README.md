# NirnAI - AI-Powered PDF Transaction Extraction System

A full-stack solution for extracting, translating, and managing Tamil real-estate transactions from PDF documents using OpenAI GPT-4.

---

## üöÄ Quick Start - Choose Your Setup Method

**üê≥ Have Docker?** ‚Üí Use Option 1 (5 minutes, fully automated)  
**üíª No Docker?** ‚Üí Use Option 2 (15 minutes, manual setup)

---

## Option 1: With Docker (Recommended - 5 Minutes)

### Prerequisites
- **Docker Desktop** ([Download](https://docs.docker.com/get-docker/))
- **OpenAI API Key** ([Get one](https://platform.openai.com/api-keys))

### Setup (One Command)

```bash
git clone <repository-url>
cd NirnAI
make setup
```

**That's it!** The setup will:
1. Check Docker installation
2. Prompt you to add OpenAI API key to `.env`
3. Build all Docker containers
4. Start all services
5. Initialize database

### Access Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:3001
- **Login**: `admin` / `admin123`

### Available Commands

```bash
make setup          # One-click setup (first time)
make start          # Start all services
make stop           # Stop all services
make restart        # Restart all services
make logs           # View all logs
make logs-backend   # Backend logs only
make logs-frontend  # Frontend logs only
make status         # Check services status
make clean          # Remove everything
make help           # Show all commands
```

---

## Option 2: Without Docker (Manual Setup - 15 Minutes)

**Quick Start with Script:**
```bash
git clone <repository-url>
cd NirnAI
./setup-manual.sh
```

**Or follow manual steps below:**

#### Prerequisites
- **Node.js 20+** ([Download](https://nodejs.org/))
- **PostgreSQL 15+** ([Download](https://www.postgresql.org/download/))
- **Redis 7+** ([Download](https://redis.io/download/))
- **OpenAI API Key** ([Get one](https://platform.openai.com/api-keys))

#### Step 1: Install Dependencies

**macOS (using Homebrew):**
```bash
# Install PostgreSQL
brew install postgresql@15
brew services start postgresql@15

# Install Redis
brew install redis
brew services start redis

# Install Node.js (if not installed)
brew install node@20
```

**Ubuntu/Debian:**
```bash
# Install PostgreSQL
sudo apt update
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql

# Install Redis
sudo apt install redis-server
sudo systemctl start redis-server

# Install Node.js 20
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt install -y nodejs
```

**Windows:**
- Install PostgreSQL from [postgresql.org](https://www.postgresql.org/download/windows/)
- Install Redis from [redis.io/download](https://redis.io/download/) or use WSL
- Install Node.js from [nodejs.org](https://nodejs.org/)

#### Step 2: Setup Database

```bash
# Create PostgreSQL database and user
psql postgres << EOF
CREATE DATABASE nirnai_db;
CREATE USER nirnai_user WITH PASSWORD 'nirnai_password';
GRANT ALL PRIVILEGES ON DATABASE nirnai_db TO nirnai_user;
ALTER DATABASE nirnai_db OWNER TO nirnai_user;
\q
EOF
```

#### Step 3: Configure Environment

```bash
# Create .env file
cp .env.example .env

# Edit .env with your settings
nano .env  # or use any text editor
```

Update these values in `.env`:
```bash
OPENAI_API_KEY=sk-proj-your-actual-key-here
DATABASE_URL=postgresql://nirnai_user:nirnai_password@localhost:5432/nirnai_db
REDIS_URL=redis://localhost:6379
JWT_SECRET=your_secure_random_string
NODE_ENV=development
NEXT_PUBLIC_API_URL=http://localhost:3001
```

#### Step 4: Install Backend Dependencies

```bash
cd backend
npm install
```

#### Step 5: Initialize Database

```bash
# Still in backend directory
npm run db:migrate
```

#### Step 6: Start Backend

```bash
# Still in backend directory
npm run start:dev
```

Backend will run on **http://localhost:3001**

#### Step 7: Install Frontend Dependencies (New Terminal)

```bash
# Open new terminal
cd frontend
npm install
```

#### Step 8: Start Frontend

```bash
# Still in frontend directory
npm run dev
```

Frontend will run on **http://localhost:3000**

#### Access Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:3001
- **Login**: `admin` / `admin123`

#### Verify Services

```bash
# Check PostgreSQL
psql -U nirnai_user -d nirnai_db -c "SELECT 1;"

# Check Redis
redis-cli ping  # Should return PONG

# Check Backend
curl http://localhost:3001

# Check Frontend
curl http://localhost:3000
```

## üéØ Project Overview

NirnAI processes 30 years of Tamil real-estate transactions from PDF documents, translates Tamil text to English, stores data in PostgreSQL, and provides a searchable web interface with side-by-side PDF preview.

## üèóÔ∏è Architecture

### Tech Stack

**Backend:**
- Node.js + NestJS (REST API)
- OpenAI GPT-4o-mini (AI-powered extraction)
- Drizzle ORM (Database management)
- PostgreSQL (Data storage)
- Redis (Caching layer)
- pdf-parse (PDF extraction)
- Transliteration service (Tamil to English)

**Frontend:**
- Next.js 14 (React framework)
- Tailwind CSS (Styling)
- React-PDF (PDF viewer)
- Axios (API client)

**Infrastructure:**
- Docker & Docker Compose
- PostgreSQL 15
- Redis 7

### System Flow

```
PDF Upload ‚Üí Parse PDF ‚Üí AI Extraction (GPT-4) ‚Üí 
Translate Tamil ‚Üí Apply Filters ‚Üí Cache Results ‚Üí Store in DB ‚Üí Return JSON
```

## üìã Features

‚úÖ **AI-Powered Extraction**: OpenAI GPT-4o-mini for accurate transaction extraction  
‚úÖ **Intelligent Caching**: Redis-based caching for instant duplicate PDF processing  
‚úÖ **Parallel Processing**: Processes large PDFs in chunks with parallel execution  
‚úÖ **Retry Mechanism**: Automatic retry with exponential backoff for reliability  
‚úÖ **Smart Chunking**: Handles large documents by splitting into manageable chunks  
‚úÖ **Token Optimization**: Optimized prompts to reduce API costs  
‚úÖ **Intelligent Fallback**: Regex-based extraction when OpenAI is not configured  
‚úÖ PDF upload and parsing  
‚úÖ Tamil text extraction and automatic transliteration  
‚úÖ Transaction filtering (buyer, seller, house no., survey no., document no.)  
‚úÖ PostgreSQL storage with Drizzle ORM  
‚úÖ RESTful API endpoints  
‚úÖ Authentication system  
‚úÖ Professional responsive UI  
‚úÖ Dedicated transactions page with Excel-like layout  
‚úÖ Transaction search and sorting  
‚úÖ CSV export functionality  
‚úÖ Loading states with progress indicators  

## üîß Configuration

## üöÄ Quick Start

### Prerequisites

- Node.js 20+
- Docker & Docker Compose
- npm or yarn

### Environment Setup

1. Clone the repository and navigate to the project:
```bash
cd NirnAI
```

2. Copy environment file:
```bash
cp .env.example .env
```

3. **Configure OpenAI API Key** (Recommended for accurate extraction):
```bash
# Edit .env and add your OpenAI API key:
OPENAI_API_KEY=sk-proj-your-key-here
```
See [OPENAI_SETUP.md](OPENAI_SETUP.md) for detailed instructions.

4. Update other `.env` values if needed (defaults work for local development)

### Option 1: Docker Compose (Recommended)

Start all services with Docker:

```bash
docker-compose up --build
```

This will start:
- PostgreSQL on port 5432
- Backend API on port 3001
- Frontend on port 3000

### Option 2: Local Development

#### Backend Setup

```bash
cd backend
npm install

# Generate database migrations
npm run db:generate

# Run migrations
npm run db:migrate

# Start backend
npm run start:dev
```

Backend will run on http://localhost:3001

#### Frontend Setup

```bash
---

## üìÇ Project Structure

```
NirnAI/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.controller.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transaction.controller.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai-extraction.service.ts    # AI extraction with chunking
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf-parser.service.ts           # PDF parsing
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.service.ts                # Redis caching
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ translation.service.ts          # Tamil transliteration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transaction.service.ts          # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema.ts                       # Drizzle schema
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db.ts                           # DB connection
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ init.ts                         # DB initialization
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ migrate.ts                      # Migration runner
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dto/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transaction.dto.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.module.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.ts
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                        # Login page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx                    # Upload interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transactions/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ page.tsx                    # Transactions table
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UploadForm.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LoadingScreen.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TransactionsTable.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.ts                          # API client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ next.config.js
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ docker-compose.yml                          # Orchestration
‚îú‚îÄ‚îÄ Makefile                                    # Build automation
‚îú‚îÄ‚îÄ setup.sh                                    # Setup script
‚îú‚îÄ‚îÄ .env.example                                # Environment template
‚îî‚îÄ‚îÄ README.md
```

---

## üèóÔ∏è Architecture

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Browser (localhost:3000)          ‚îÇ
‚îÇ  Next.js 14 + React + TailwindCSS           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ HTTP/REST
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      NestJS Backend (localhost:3001)        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Controllers                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Auth ‚Ä¢ Transaction               ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ              ‚ñº                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Services                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ OpenAI Extraction (GPT-4o-mini)  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ PDF Parser (pdf-parse)           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Cache Service (Redis)            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Translation (Transliteration)    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ              ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇPostgreSQL‚îÇ  ‚îÇ  Redis   ‚îÇ
   ‚îÇPort: 5433‚îÇ  ‚îÇPort: 6379‚îÇ
   ‚îÇ  Drizzle ‚îÇ  ‚îÇ  Cache   ‚îÇ
   ‚îÇ    ORM   ‚îÇ  ‚îÇ  Layer   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Processing Flow

```
1. PDF Upload ‚Üí 
2. Parse PDF (pdf-parse) ‚Üí Extract Text ‚Üí 
3. Check Cache (SHA-256 hash) ‚Üí 
   ‚îú‚îÄ Cache Hit: Return Cached Results (<1s)
   ‚îî‚îÄ Cache Miss: Continue...
4. Split into Chunks (15k tokens each) ‚Üí 
5. Parallel Processing (2 chunks at a time) ‚Üí
6. OpenAI GPT-4o-mini Extraction ‚Üí 
7. Retry Mechanism (3 attempts, exponential backoff) ‚Üí 
8. Transliteration (Tamil ‚Üí English) ‚Üí 
9. Apply Filters ‚Üí 
10. Store in PostgreSQL ‚Üí 
11. Cache Results (24h TTL) ‚Üí 
12. Return JSON
```

---

## üéØ Features

### Core Features
‚úÖ **AI-Powered Extraction** - GPT-4o-mini with optimized prompts
‚úÖ **Intelligent Caching** - Redis with SHA-256 deduplication
‚úÖ **Parallel Processing** - Handles large PDFs with chunking
‚úÖ **Retry Mechanism** - 3 attempts with exponential backoff
‚úÖ **Token Optimization** - 60% reduction in API costs
‚úÖ **Tamil Transliteration** - Unicode to English conversion
‚úÖ **Professional UI** - Modern gradient design
‚úÖ **Excel-like Table** - Search, sort, export functionality
‚úÖ **Authentication** - JWT-based security

### Performance Optimizations
- **Chunking**: 15k tokens per chunk (respects rate limits)
- **Parallel**: Processes 2 chunks simultaneously
- **Caching**: Duplicate PDFs return in <1 second
- **Prompt**: Optimized from 800 to 200 characters
- **Tokens**: Reduced max_tokens from 16k to 8k

---

## üóÑÔ∏è Database Schema

```sql
CREATE TABLE transactions (
  id SERIAL PRIMARY KEY,
  buyer_name TEXT,
  buyer_name_tamil TEXT,
  seller_name TEXT,
  seller_name_tamil TEXT,
  house_number TEXT,
  survey_number TEXT,
  document_number TEXT,
  transaction_date TEXT,
  transaction_value NUMERIC,
  district TEXT,
  village TEXT,
  additional_info TEXT,
  pdf_file_name TEXT,
  extracted_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Indexes for fast search
CREATE INDEX idx_buyer ON transactions(buyer_name);
CREATE INDEX idx_seller ON transactions(seller_name);
CREATE INDEX idx_survey ON transactions(survey_number);
CREATE INDEX idx_document ON transactions(document_number);
```

---

## üîß Configuration

### Environment Variables (`.env`)

```bash
# Required
OPENAI_API_KEY=sk-proj-your-key-here

# Database (auto-configured for Docker)
DATABASE_URL=postgresql://nirnai_user:nirnai_password@postgres:5432/nirnai_db

# Redis (auto-configured for Docker)
REDIS_URL=redis://redis:6379

# Security
JWT_SECRET=change_this_in_production

# Optional
NODE_ENV=development
NEXT_PUBLIC_API_URL=http://localhost:3001
```

---

## üß™ Testing the Application

### 1. Upload a PDF
1. Login with `admin` / `admin123`
2. Click "Choose PDF File"
3. Select a Tamil property transaction PDF
4. (Optional) Add filters
5. Click "Upload & Extract"

### 2. View Processing

**With Docker:**
```bash
make logs-backend  # Watch AI extraction in real-time
```

**Without Docker:**
Check the terminal where you ran `npm run start:dev`

### 3. Check Results
- View transactions in Excel-like table
- Search by any field
- Sort columns
- Export to CSV

### 4. Test Caching
- Upload same PDF again
- Notice instant results (<1 second)

---

## ‚ùì Troubleshooting

### Docker Setup Issues

| Issue | Solution |
|-------|----------|
| Docker not running | Start Docker Desktop |
| Port 3000 in use | Run `make clean` then `make setup` |
| Database migration failed | Run `make db-init` |
| OpenAI API error | Check API key in `.env` and account credits |
| Redis connection failed | Run `docker-compose restart redis` |
| Backend not responding | Run `make logs-backend` to check errors |

### Manual Setup Issues

| Issue | Solution |
|-------|----------|
| PostgreSQL not found | Install: `brew install postgresql@15` (Mac) or `sudo apt install postgresql` (Linux) |
| PostgreSQL not starting | Mac: `brew services start postgresql@15`<br>Linux: `sudo systemctl start postgresql` |
| Database access denied | Run: `psql -U postgres` then create user manually |
| Redis not found | Install: `brew install redis` (Mac) or `sudo apt install redis-server` (Linux) |
| Redis not running | Mac: `brew services start redis`<br>Linux: `sudo systemctl start redis-server` |
| Port 3000 already in use | Kill process: `lsof -ti:3000 \| xargs kill -9` |
| Port 3001 already in use | Kill process: `lsof -ti:3001 \| xargs kill -9` |
| npm install fails | Clear cache: `npm cache clean --force` then retry |
| Backend won't start | Check logs in terminal, ensure PostgreSQL and Redis are running |
| Frontend build error | Delete `node_modules` and `.next`, run `npm install` again |
| Database migration error | Ensure database exists: `psql -U postgres -l \| grep nirnai_db` |

### Connection Issues

**Backend can't connect to PostgreSQL:**
```bash
# Check if PostgreSQL is running
psql -U postgres -c "SELECT 1;"

# Verify database exists
psql -U postgres -l | grep nirnai_db

# Test connection with credentials
psql -U nirnai_user -d nirnai_db -c "SELECT 1;"
```

**Backend can't connect to Redis:**
```bash
# Check if Redis is running
redis-cli ping  # Should return PONG

# Check Redis connection
redis-cli
> INFO
> quit
```

**Frontend can't connect to Backend:**
```bash
# Check backend is running
curl http://localhost:3001

# Check NEXT_PUBLIC_API_URL in .env
cat .env | grep NEXT_PUBLIC_API_URL

# Restart frontend after changing .env
cd frontend
npm run dev
```

### OpenAI API Issues

| Issue | Solution |
|-------|----------|
| "Invalid API Key" | Verify key in `.env` starts with `sk-proj-` or `sk-` |
| "Rate limit exceeded" | Wait a few minutes, or upgrade OpenAI plan |
| "Insufficient quota" | Add credits to OpenAI account |
| "Model not found" | Check OpenAI account has access to GPT-4o-mini |

---

## üõ†Ô∏è Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Next.js 14, React, TypeScript, TailwindCSS |
| **Backend** | NestJS, Node.js 20, TypeScript |
| **AI** | OpenAI GPT-4o-mini API |
| **Database** | PostgreSQL 15, Drizzle ORM |
| **Cache** | Redis 7, ioredis |
| **PDF** | pdf-parse |
| **Containerization** | Docker, Docker Compose |
| **Authentication** | JWT |

---

## ‚ùì Troubleshooting

| Issue | Solution |
|-------|----------|
| Docker not running | Start Docker Desktop |
| Port 3000 in use | Run `make clean` then `make setup` |
| Database migration failed | Run `make db-init` |
| OpenAI API error | Check API key in `.env` and account credits |
| Redis connection failed | Run `docker-compose restart redis` |
| Backend not responding | Run `make logs-backend` to check errors |

---

## üìù API Endpoints

### Authentication
```
POST /auth/login
Body: { username, password }
Returns: { accessToken, user }
```

### Transactions
```
POST /transactions/upload
Form: pdf (file), filters (optional)
Returns: { transactions[], totalExtracted, totalFiltered }

GET /transactions
Query: buyerName, sellerName, surveyNumber, etc.
Returns: { transactions[] }
```

---

## üöÄ Performance Metrics

- **Small PDF (10 pages)**: ~10-15 seconds
- **Medium PDF (50 pages)**: ~30-45 seconds  
- **Large PDF (100+ pages)**: ~60-90 seconds
- **Cached PDF**: <1 second
- **Token usage**: ~5k-8k per chunk
- **API calls**: 1 call per 15k tokens

---

## üéì How It Works

### AI Extraction Process
1. **PDF Parsing**: Extract raw text using pdf-parse
2. **Chunking**: Split large documents into 15k token chunks  
3. **OpenAI Processing**: Send to GPT-4o-mini with optimized prompts
4. **Parallel Execution**: Process 2 chunks simultaneously
5. **Retry Logic**: 3 attempts with exponential backoff
6. **Transliteration**: Convert Tamil ‚Üí English phonetics
7. **Caching**: Store in Redis with SHA-256 hash
8. **Storage**: Save to PostgreSQL with indexes

### Fallback Strategy
If OpenAI unavailable ‚Üí Automatic regex-based extraction

---

## üîê Security

- JWT authentication
- Default credentials for demo: `admin` / `admin123`
- Change `JWT_SECRET` in production
- `.env` not committed to git
- CORS configured

---

**Need help? Run `make logs` to check logs**

# NirnAI-Assignment
